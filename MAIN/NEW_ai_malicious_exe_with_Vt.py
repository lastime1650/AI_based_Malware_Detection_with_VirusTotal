import struct

import pandas as pd
import tensorflow as tf
import numpy as np
import pefile
import pickle
import threading

from AI_Server.VirusTotal_analyse.virust_total_api import VirusTotal_class
from AI_Server.dynamic_analyse.Dynamic_analyse import Dynamic_Analyse_Class_normal

import io
import os
from AI_Server.Parsing_CSV import Open_Csv # CSV편집기
class AI_Static_Model_with_Vt():

    def EXE_to_SHA256(self, EXE_binary:bytes=None)-> str:
        if EXE_binary == None : return None

        import hashlib
        HASHED = hashlib.sha256(EXE_binary).hexdigest()
        print(f"EXE sha256 해시 결과 -> {HASHED}")
        return HASHED

    def collect_ALL(self): # 데이터를 모으기전 데이터세트의 중복제외 모든 DLL과 API를 수집한다.
        try:
            for data in self.pe.DIRECTORY_ENTRY_IMPORT:
                #print(data.dll.decode("utf8"))
                if not data.dll.decode("utf8") in self.dll_list:
                    self.dll_list.append( data.dll.decode("utf8") )

                for imports_data in data.imports:
                    #print(f'{x} >> {imports_data.name}')
                    if imports_data.name == None:
                        continue
                    if not imports_data.name.decode("utf8") in self.apis:
                        self.apis.append(imports_data.name.decode('utf8'))
                    else:
                        continue
        except:
            print('DIRECTORY_ENTRY_IMPORT 가 없음!')

        #print(f'DLL 정보 -> {self.dll_list}\nAPI 정보 -> {self.apis}\n')


        for i in self.pe.sections:
            name = str(i.Name.decode("utf8")).strip('\x00')
            # print(f'{x} >> {name}')
            if not name in self.section_name_list:
                self.section_name_list.append(name)
        #print(f'self.section_name 정보 -> {self.section_name_list}')

    def Important_2_make_X(self, Train_Mode: bool=True, EXE_Binary:bytes = None, VT_instance:VirusTotal_class = None, Dynamic_analyser:Dynamic_Analyse_Class_normal = None):

        if VT_instance == None:
            print("Important_2_make_X -> VT_instance 각 None이라 X값 만들 수 없음!")

        if Dynamic_analyser == None:
            print("Important_2_make_X -> Dynamic_analyser None이라 X값 만들 수 없음!")

        if EXE_Binary == None:
            for exe_path in self.exe_path:
                self.pe = pefile.PE(name=exe_path)
        else:
            self.pe = pefile.PE(data=EXE_Binary)
        self.collect_ALL()  # 모든 정보 긁어모으기

        '''[2]-2. 시그니처 목록'''
        self.api_signature1 = ["openprocess",
                               "virtualallocex",
                               "writeprocessmemory",
                               "loadlibrarya",
                               "loadresource",
                               "getprocaddress",
                               "createremotethread",
                               "writefile",
                               "istrcmpia",
                               "readfile",
                               "deletefilea",
                               "copyfilea",
                               "createprocessa",
                               "findfirstfilea",
                               "createprocess",
                               "getwindowsdirectory",
                               "regsetvalueexa",
                               "regenumvaluea",
                               "regdeletekeya",
                               "regcreatekeyexa",
                               "openprocesstoken",
                               "cryptcreatehash",
                               "crypthashdata",
                               "cryptgethashparam",
                               "cryptacquirecontexta",
                               "writefile",
                               "readfile",
                               "createfile",
                               "copyfile",
                               "movefile",
                               "ntquerydirectoryfile",
                               "createfilea",
                               "createfilew",
                               "loadlibrary",
                               "createthread",
                               "resumethread",
                               "createremotethread",
                               "mouse_event",
                               "keybd_event",
                               "getasynckeystate",
                               "attachthreadinput",
                               "internetwritefile",
                               "internetconnect",
                               "internetopenurl",
                               "internetreadfile",
                               "wsastartup",
                               "gethostbyname",
                               "gethostbyaddr",
                               "socket",
                               "send_recv",
                               "inet_addr",
                               "bind",
                               "connect",
                               "accept",
                               "connectnamepipe",
                               "urldownloadtofile",
                               "netshareenum",
                               "ftpopenfile",
                               "ftpgetfilesize",
                               "shellexecute",
                               "sfcterminatewatcherthread",
                               "samqueryinformationuse",
                               "openmutex",
                               "outputdebugstring",
                               "isntadmin",
                               "iswow64process",
                               "virtualallocex",
                               "virtualprotectex",
                               "writeprocessmemory"

                               ]

        # self.X = self.dll_list + self.apis + self.section_name_list  # 모든 정보 1차 결합
        if Train_Mode:
            self.X = self.dll_list + self.apis + self.section_name_list + self.api_signature1
        else:
            pass

        result_X = []
        if EXE_Binary == None:
            for index, exe_path in enumerate(self.exe_path):
                tmp_result_X = self.Make_result_X(exe_path=exe_path,VT_instance=VT_instance,Dynamic_analyser=Dynamic_analyser) # None일 경우바로 종료해야함
                if (tmp_result_X == None): return None
                result_X.append( tmp_result_X  )# csv 데이터세트에 있는 exe절대경로를 반복적으로 읽어 2차원 X값(result_X) 생성
                print(f"현재 훈련중 result_X 길이 -> {len(result_X[index])}")
        else:
            tmp_result_X = self.Make_result_X(exe_binary=EXE_Binary,VT_instance=VT_instance,Dynamic_analyser=Dynamic_analyser)
            if (tmp_result_X == None): return None
            result_X.append(tmp_result_X) # 이친구는 Prediction 메서드에서 사용되는 경우가 크다.
        print(f"np.asarray 하기 직전, result_X 값 -> {result_X} ")

        result_X = np.asarray(result_X, dtype=object)
        return result_X

    def Make_result_X(self, exe_path:str = None, exe_binary:bytes= None,VT_instance:VirusTotal_class = None, Dynamic_analyser:Dynamic_Analyse_Class_normal = None)->list:
        if VT_instance == None:
            print("Make_result_X -> VT_instance가 None이라 하나의 X값 생성불가!")
            return None

        if Dynamic_analyser == None:
            print("Make_result_X -> Dynamic_analyser None이라 하나의 X값 생성불가!")
            return None


        tmp = []
        SHA256=''
        if exe_binary == None:
            self.pe = pefile.PE(name=exe_path)
            print(f"--------->> {exe_path} ")
            tmp = b''
            with open(exe_path, 'rb') as f:
                tmp = f.read()
            SHA256 = self.EXE_to_SHA256(tmp)
        else:
            self.pe = pefile.PE(data=exe_binary)
            SHA256 = self.EXE_to_SHA256(exe_binary)

        '''[1]'''
        try:
            for filter_word in self.X:
                default_value = 0
                is_found = False
                '''dll api 0 또는 1 취하기'''

                for data in self.pe.DIRECTORY_ENTRY_IMPORT:

                    if is_found:
                        break

                    if data.dll.decode("utf8").lower() in filter_word: # DLL 포함 여부
                        tmp.append(1)
                        is_found = True
                        break

                    for imports_data in data.imports:

                        if is_found:
                            break

                        if imports_data.name == None:
                            continue
                        if imports_data.name.decode("utf8").lower() in filter_word: # API 포함 여부
                            tmp.append(1)
                            is_found = True
                            break
                        else:
                            continue

                if is_found == False:
                    tmp.append(0)
        except:
            print('DIRECTORY_ENTRY_IMPORT 가 없습니다!')
            tmp = [0] * len(self.X)  # 없는 경우 싹다 0 처리

        # print(len(tmp))
        '''[2]'''
        '''hex기반 text 탐지'''
        self.signature_text = [b'windows', b'Windows', b'telnet', b'Telnet', b'ssh', b'Ssh', b'SSH', b'ftp', b'ftp',
                               b'ftp-server', b'FTP-Server',
                               b'rdp', b'rdp.exe', b'RDP', b'C:\\', b'C:\\Windows', b'hosts.exe', b'Hosts.exe',
                               b'regedit', b'Regedit.exe', b'Registry', b'registry',
                               b'appdata', b'AppData', b'APPDATA', b'%AppData%', b'%appdata%', b'Program',
                               b'Programs',
                               b'Program Files', b'Program Files (x86)',
                               b'C:\\Users', b'Users', b'User', b'users', b'C:\\Users\\Administrator',
                               b'administrator',
                               b'Administrator', b'admin']
        if exe_binary == None:
            with open(exe_path, "rb") as f1:
                text_tmp = []
                exe_data = f1.read()
                for i in self.signature_text:
                    if i in exe_data:
                        text_tmp.append(1)
                    else:
                        text_tmp.append(0)
        else:
            text_tmp = []
            for i in self.signature_text:
                if i in exe_binary:
                    text_tmp.append(1)
                else:
                    text_tmp.append(0)

        '''pe 분석 '''

        VA = [i.VirtualAddress for i in self.pe.OPTIONAL_HEADER.DATA_DIRECTORY]
        Sz = [i.Size for i in self.pe.OPTIONAL_HEADER.DATA_DIRECTORY]

        if len(VA) == 15:
            VA += [0]
        if len(Sz) == 15:
            Sz += [0]

        self.signature_pe_obj = [  # [i.VirtualAddress for i in self.pe.OPTIONAL_HEADER.DATA_DIRECTORY],
            # [i.Size for i in self.pe.OPTIONAL_HEADER.DATA_DIRECTORY],
            VA, Sz,

            self.pe.DOS_HEADER.e_magic, self.pe.DOS_HEADER.e_cblp, self.pe.DOS_HEADER.e_cp,
            self.pe.DOS_HEADER.e_crlc,
            self.pe.DOS_HEADER.e_cparhdr, self.pe.DOS_HEADER.e_minalloc,
            self.pe.DOS_HEADER.e_maxalloc,
            self.pe.DOS_HEADER.e_ss, self.pe.DOS_HEADER.e_sp, self.pe.DOS_HEADER.e_csum,
            self.pe.DOS_HEADER.e_ip,
            self.pe.DOS_HEADER.e_cs, self.pe.DOS_HEADER.e_lfarlc, self.pe.DOS_HEADER.e_oemid,
            self.pe.DOS_HEADER.e_oeminfo,
            self.pe.DOS_HEADER.e_lfanew,

            self.pe.FILE_HEADER.Machine, self.pe.FILE_HEADER.NumberOfSections,
            self.pe.FILE_HEADER.PointerToSymbolTable, self.pe.FILE_HEADER.NumberOfSymbols,
            self.pe.FILE_HEADER.SizeOfOptionalHeader, self.pe.FILE_HEADER.Characteristics,

            self.pe.OPTIONAL_HEADER.Magic, self.pe.OPTIONAL_HEADER.MajorLinkerVersion,
            self.pe.OPTIONAL_HEADER.MinorLinkerVersion, self.pe.OPTIONAL_HEADER.SizeOfCode,
            self.pe.OPTIONAL_HEADER.SizeOfInitializedData,
            self.pe.OPTIONAL_HEADER.SizeOfUninitializedData,
            self.pe.OPTIONAL_HEADER.AddressOfEntryPoint, self.pe.OPTIONAL_HEADER.BaseOfCode,
            self.pe.OPTIONAL_HEADER.ImageBase, self.pe.OPTIONAL_HEADER.SectionAlignment,
            self.pe.OPTIONAL_HEADER.FileAlignment,
            self.pe.OPTIONAL_HEADER.MajorOperatingSystemVersion,
            self.pe.OPTIONAL_HEADER.MinorOperatingSystemVersion,
            self.pe.OPTIONAL_HEADER.MajorImageVersion,
            self.pe.OPTIONAL_HEADER.MinorImageVersion,
            self.pe.OPTIONAL_HEADER.MajorSubsystemVersion,
            self.pe.OPTIONAL_HEADER.MinorSubsystemVersion, self.pe.OPTIONAL_HEADER.Reserved1,
            self.pe.OPTIONAL_HEADER.SizeOfImage, self.pe.OPTIONAL_HEADER.SizeOfHeaders,
            self.pe.OPTIONAL_HEADER.CheckSum, self.pe.OPTIONAL_HEADER.Subsystem,
            self.pe.OPTIONAL_HEADER.DllCharacteristics,
            self.pe.OPTIONAL_HEADER.SizeOfStackReserve,
            self.pe.OPTIONAL_HEADER.SizeOfStackCommit,
            self.pe.OPTIONAL_HEADER.SizeOfHeapReserve,
            self.pe.OPTIONAL_HEADER.SizeOfHeapCommit,
            self.pe.OPTIONAL_HEADER.LoaderFlags, self.pe.OPTIONAL_HEADER.NumberOfRvaAndSizes
        ]
        # print(len(self.signature_pe_obj))

        self.sig = []
        [self.sig.extend(i) if isinstance(i, list) else self.sig.append(i) for i in
         self.signature_pe_obj]  # 리스트 중 중첩 리스트를 extend 처리 후 다시 재구성

        tmp += self.sig
        tmp += text_tmp
        # print('\n')

        '''[3] (VT 분석의 경우 Vt 분석을 넣도록 한다 ) '''
        '''
            VT 객체를 통하여 Start_Scan 실시.
            단, Open_Csv할 때, 이미 분석된 파일의 VT값이 CSV에 있으면, 바로 불러온다. 
        '''
        print("Vt분석 시작(테스트)")
        csv_inst = Open_Csv(self.VT_analyse_csv)
        VT_analysed_list = csv_inst.Output_one_row(SHA256, 0)  # 이미 VT분석된 적이 있는지 확인
        result_x_of_VT_analyse = None # VT결과물이 들어갈 공간
        if (VT_analysed_list == None):
            print(f"이전 VT분석 기록이 '{self.VT_analyse_csv}'에 없으며, 새로 생성합니다.")
            result_bool , result_list, result_bytes = False, None, None
            try:
                if exe_binary == None: # 훈련
                    result_bool , result_list, result_bytes =VT_instance.Start_Scan(
                        Binary_DATA=None,
                        Path=exe_path,
                        Binary_DATA_SHA256=None  # 이것은 임시로 None
                    )
                else: # 예측
                    result_bool , result_list, result_bytes = VT_instance.Start_Scan(
                        Binary_DATA=exe_binary,
                        Path=None,
                        Binary_DATA_SHA256=None  # 이것은 임시로 None
                    )
            except:
                print("VirusTotal API  횟수가 초과되어 예측 및 훈련이 진행되지 않은 것 같습니다.")
                return None
            FILE_SHA256 = str(result_list[0][0]) # VT

            #print(f"self.VT.Start_Scan 결과 -> ",result_bool , result_list, result_bytes)
            from AI_Server.Vt_analyse_data_to_machineLearning_data import Vt_analysed_List__To__machineLearning_list

            # 이미 VT분석된 적이 있는지 확인

            result_x_of_VT_analyse = Vt_analysed_List__To__machineLearning_list(
                input_vt_list=result_list
            )
            '''CSV에 {vt}반영'''

            csv_inst.APPEND_row([FILE_SHA256]+result_x_of_VT_analyse) # VT분석 결과 반영
        else:
            print(f"이전 VT분석 기록이 '{self.VT_analyse_csv}'에 있습니다.")
            result_x_of_VT_analyse = VT_analysed_list[1:len(VT_analysed_list)]
        tmp += result_x_of_VT_analyse

        '''
            [NEW] + 그냥 모델을 통합하기로함. 
            정적 + vt + 동적 으로 구현할 것이다. 
            
            이 주석까지 실행했다면,,
            
            한 EXE 파일에 대해 정적 + vt 까지 완료됨. 
            
            이제 동적분석하자
            
        '''
        #if exe_binary == None: # 훈련
            #Get_Usermode_X_data, Get_Kernelmode_X_data = Dynamic_analyser.Run_Listening(Path= exe_path) # 동적분석 시작 메서드 ( 서버 소켓 열기 )
        #else: # 예측
            #Get_Usermode_X_data, Get_Kernelmode_X_data = Dynamic_analyser.Run_Listening(Binary_DATA=exe_binary) # 동적분석 시작 메서드 ( 서버 소켓 열기 )
        #print(f"Get_Usermode_X_data -> {Get_Usermode_X_data} 그리고 길이 -> {len(Get_Usermode_X_data)}")

        #tmp += Get_Usermode_X_data

        '''
            정적 + vt + 동적 성공!
        '''
        #result_X.append(tmp)
        #한 exe 분석 결과 리스트를 return
        return tmp

    def Make_Train_Data(self, is_Train_mode: bool=True,exe_binary:bytes=None, VT_instance:VirusTotal_class=None, Dynamic_analyser:Dynamic_Analyse_Class_normal=None):

        if VT_instance == None:
            print("Make_Train_Data -> VT_instance 가 None!")
            return

        if Dynamic_analyser == None:
            print("Make_Train_Data -> Dynamic_analyser 가 None!")
            return

        if is_Train_mode:
            '''원-핫 인코드'''
            self.y_for_one_hot = []
            for i in self.exe_type:
                if not i in self.y_for_one_hot:
                    self.y_for_one_hot.append(i)

            self.y = []  # 원핫인코드 최종저장
            for i in self.exe_type:
                tmp = [0] * len(self.y_for_one_hot)
                tmp[self.y_for_one_hot.index(i)] = 1
                self.y.append(tmp)
            self.y = np.array(self.y)
            print(self.y)

            with open(f'{self.save_index}_y', 'wb') as f:
                pickle.dump(self.y_for_one_hot, f,protocol=5)

            '''[2] 모두 수집용'''
            self.dll_list = []  # DLL 전역정보
            self.apis = []  # API 전역정보
            self.optional_header_data_dir_list = []
            self.section_name_list = []


            '''
                아래 exe경로를 사용해서 X값을 만드는 녀석임 
            '''
            result_X = self.Important_2_make_X(EXE_Binary=exe_binary,VT_instance=VT_instance,Dynamic_analyser=Dynamic_analyser) # 중요! X 값을 만들어주는 클래스로 prediction할 때도 필요!
            if result_X == None : return None, None, None, None # VT 이슈에 의해 None
            with open(f'{self.save_index}_X', 'wb') as f:
                pickle.dump(self.X,f,protocol=5)

            print(f"완성된 result_X-> {result_X}");
            for index, data in enumerate(result_X):
                print(f"[{index}]번째 -> X값  {data}\n")
            '''
                (Vt)할거면 여기서 바이러스 토탈 해야함
            '''
            '''
                (Vt) - END  result_X 와 결합해야한다.
            '''
            from sklearn.preprocessing import MinMaxScaler
            self.scalar = MinMaxScaler()
            self.X = self.scalar.fit_transform(result_X)

            print(f"최종 X 값 -> {self.X} / X 값 길이 -> {len(self.X)}")
            print(self.y)
            print(
                f'self.X길이 -> {len(self.X)} 속성 길이 -> {len(self.X[0])}\nself.Y길이 -> {len(self.y)} 속성길이 -> {len(self.y[0])}')

            from sklearn.model_selection import train_test_split
            x_train, x_valid, y_train, y_valid = train_test_split(self.X, self.y, test_size=0.2)

            with open(f'{self.save_index}_scalar', 'wb') as f:
                pickle.dump(self.scalar, f,protocol=5)
                print('데이터 전처리기 성공')


            return x_train, x_valid, y_train, y_valid
        else:


            result_X = self.Important_2_make_X(False,EXE_Binary=exe_binary,VT_instance=VT_instance,Dynamic_analyser=Dynamic_analyser)  # 중요! else문일때며, Train모드가 '아닐 때' 작동되는 코드영역 # False -> Prediction Mode
            if result_X == None : return None

            return result_X



    #VT API값은 호출마다 가져올 수 있도록 함 . 생성자에서 안보내도, 훈련/얘축시 넘겨도 됨!(이유: 즉시 VT인스턴스를 만듦 )
    def __init__(self, Vt_API:str =None , csv_path:str = None, VT_analyse_csv:str=None, save_index_For_PATH: str='New_Malicious_Detection', LOCK = threading.Lock ,default_retrain_count:int = 100):

        '''

            흠.. 훈련할 떄 최신의 CSV를 읽어와서 훈련한다음.
            zip으로 훈련한 현 CSV를 저장하는 형태로 해야하는데...
        '''


        if Vt_API == None:
            print("[정적 +Vt분석 모델 생성자] 현재 API 가 설정되어 있지 않습니다.. ")
            self.VT_API = None
        else:
            self.VT_API = Vt_API

        if VT_analyse_csv == None:
            print("VT_analyse_csv 경로를 설정해주십시오")
            self.VT_analyse_csv = None
            return
        else :
            self.VT_analyse_csv = VT_analyse_csv

        df = pd.read_csv(csv_path)
        self.Main_csv = csv_path
        #print( df['sha256'] )
        self.List_type_Dataset_from_Pickle = [] # [0]:sha256,[1]:path_when_train,[2]:Y

        self.exe_path = [str(i) for i in df['values']]
        self.exe_sha256 = [ f'{i}' for i in df['sha256']]
        self.exe_type = [f'{i}' for i in df['types']]

        self.save_index = save_index_For_PATH
        try:
            List_type_Dataset = []
            with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'rb') as f:
                List_type_Dataset = pickle.load(f)
            if len(List_type_Dataset) > 0:
                self.List_type_Dataset_from_Pickle = List_type_Dataset
            else:
                self.List_type_Dataset_from_Pickle = [i for i in zip(self.exe_path,self.exe_sha256,self.exe_type)]
        except:
            print(f"{self.save_index}_List_type_Dataset_from_Pickle 가 존재하지 않아, CSV 파일을 읽어, 새로저장하겠습니다")
            self.List_type_Dataset_from_Pickle = [i for i in zip(self.exe_path,self.exe_sha256,self.exe_type)]


        #self.List_type_Dataset_from_Pickle = [i for i in zip(self.exe_path,self.exe_sha256,self.exe_type)]
        print( [ i for i in self.List_type_Dataset_from_Pickle] )



        self.save_index = save_index_For_PATH # 저장시 파일명 저장에 사용
        self.scalar = None

        self.Model_LOCK =LOCK

        self.re_train_count_increasement = 0
        self.re_train_count = default_retrain_count # re_train_count_increasement값이 이 변수값이 되면 자동으로 재훈련.

        with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'wb') as f: # 훈련성공 시, CSV 저장
            pickle.dump( self.List_type_Dataset_from_Pickle,f,protocol=5)

    def Start_Train(self, Vt_API:str = None,csv_path:str = None, epoch: int=100, batch_size: int=10, validation_split_num: float=0.2):

        # 훈련하기 전, 최신의 CSV 정보를 다시 가져오자
        if csv_path == None:

            List_type_Dataset = []
            with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'rb') as f:
                List_type_Dataset = pickle.load(f)
            if len([i for i in List_type_Dataset]) < 1:
                print([i for i in List_type_Dataset])
                print(f"List_type_Dataset 가 존재하지 않음!..")
                return None, None, None
            print(List_type_Dataset)

            self.exe_path = [f'{i[0]}' for i in List_type_Dataset ]
            self.exe_sha256 = [f'{i[1]}' for i in List_type_Dataset ]
            self.exe_type = [f'{i[2]}' for i in List_type_Dataset ]
        else:
            df = pd.read_csv(csv_path)
            self.exe_sha256 = [f'{i}' for i in df['sha256']]
            self.exe_path = [rf'{i}' for i in df['values']]
            self.exe_type = [f'{i}' for i in df['types']]


        if Vt_API == None:
            if self.VT_API == None:
                print("Vt_API 값을 주십시오")
                return None, None, None
            else:
                VT_instance = VirusTotal_class(self.VT_API)
        else:
            VT_instance = VirusTotal_class(Vt_API)



        print("test1 동적분석 인스턴스 로드")
        Dynamic_analyse_instance = Dynamic_Analyse_Class_normal() # 동적분석 인스턴스

        x_train, x_valid, y_train, y_valid = self.Make_Train_Data(exe_binary=None,VT_instance=VT_instance,Dynamic_analyser=Dynamic_analyse_instance) # exe_binary 가 None이면 self.Path ( list[str]로 exe여러개 읽는 것을 의미.)
        if x_train == None or  x_valid == None or  y_train == None or y_valid == None : print("VT 이슈 발생으로 훈련 실패")
        X_model_input = tf.keras.layers.Input(shape=(len(self.X[0]),))
        X_model_output = tf.keras.layers.Dense(64, activation='relu')(X_model_input)
        X_model_output = tf.keras.layers.Dense(64, activation='relu')(X_model_input)
        X_model_output = tf.keras.layers.Dropout(0.2)(X_model_input)
        X_model_output = tf.keras.layers.Dense(64, activation='relu')(X_model_input)
        X_model_output = tf.keras.layers.Dense(32, activation='relu')(X_model_input)
        X_model_output = tf.keras.layers.Dense(32, activation='relu')(X_model_input)
        X_model_output = tf.keras.layers.Dense(len(self.y[0]), activation='softmax')(X_model_input)

        result_model = tf.keras.Model(inputs=X_model_input, outputs=X_model_output)
        result_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])
        result_model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epoch, validation_data=(x_valid, y_valid),
                         validation_split=validation_split_num)

        result_model.save(f'{self.save_index}_model') # 세이브

        print("List_type_Dataset_from_Pickle 를 저장하겠습니다. (현 최신의 CSV를 훈련하고 저장하는 것)")
        with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'wb') as f: # 훈련성공 시, CSV 저장
            pickle.dump(self.List_type_Dataset_from_Pickle,f,protocol=5)


    def Prediction(self, Vt_API:str = None, EXE_PATH: str = None , EXE_Binary: bytes = None)->(list, bytes, str):# 원핫인코드y , 제일높은 float값을 pack한 bytes, predict결과, 판단된 문자열
        if Vt_API == None:
            if self.VT_API == None:
                print("Vt_API 값을 주십시오")
                return None, None, None
            else:
                VT_instance = VirusTotal_class(self.VT_API)
        else:
            VT_instance = VirusTotal_class(Vt_API)

        print("test1-1 동적분석 인스턴스 로드")
        #Dynamic_analyse_instance =   # 동적분석 인스턴스

        EXE_Binary_for_prediction = b''
        if EXE_PATH:
            print(f"[문자열 모드] {EXE_PATH}를 전송받았습니다.")
            with open(EXE_PATH, 'rb') as f:
                EXE_Binary_for_prediction = f.read()
        elif EXE_Binary:
            print(f"[바이너리 모드] {EXE_Binary}를 전송받았습니다.")
            EXE_Binary_for_prediction = EXE_Binary
        else:
            return None, None, None
        #print(f"{EXE_PATH}를 전송받았습니다.")

        # CSV 기록 로드하고 CSV에 기록/축적한다. -1
        List_type_Dataset = []
        with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'rb') as f:
            List_type_Dataset = pickle.load(f)
        if len([i for i in List_type_Dataset]) < 1:
            print(f"List_type_Dataset 가 존재하지 않음!..")
            return None, None, None
        print([i for i in List_type_Dataset])



        # 모델 로드
        model = tf.keras.models.load_model(f'{self.save_index}_model')
        scalar = None
        y = None
        x_for_filter = None

        # scalar 로드
        with open(f'{self.save_index}_scalar', 'rb') as f:
            scalar = pickle.load(f)
            print('데이터 전처리기 성공')

        # 예측을 위한 추가적 X 필터 리스트 로드
        self.dll_list = []  # DLL 전역정보
        self.apis = []  # API 전역정보
        self.optional_header_data_dir_list = []
        self.section_name_list = []
        with open(f'{self.save_index}_X', 'rb') as f:
            x_for_filter = pickle.load(f)
            print(x_for_filter)
            self.X = x_for_filter

        # Y 값 로드
        with open(f'{self.save_index}_y', 'rb') as f:
            y = pickle.load(f)

        # exe 경로


        if scalar != None and model != None: # 정상적으로 불러온 경우
            if EXE_Binary == None:
                self.exe_path = [EXE_PATH]
                X = self.Make_Train_Data(False,exe_binary=None,VT_instance=VT_instance,Dynamic_analyser=Dynamic_Analyse_Class_normal()) # False -> Prediction Mode
            else:
                self.exe_path = None
                X = self.Make_Train_Data(False,exe_binary=EXE_Binary,VT_instance=VT_instance,Dynamic_analyser=Dynamic_Analyse_Class_normal())  # False -> Prediction Mode
            if X == None : return None, None, None
            
            print(X)
            print(len(X[0]))

            X = scalar.transform(X)# Scalar 전처리

            result = model.predict(X)

            print(result)
            Max_index = np.argmax(result)

            print(y[Max_index])

            # SHA256을 구하고 중복 검사 . 중복이 아니면 축적하고 재저장-2
            Get_sha256_from_exe: str = self.EXE_to_SHA256(EXE_Binary_for_prediction)
            if not( any(csv_data[1] == Get_sha256_from_exe for csv_data in List_type_Dataset) ): # csv_data에 없을 때
                with open(f".\\{Get_sha256_from_exe}.exe", 'wb') as f:# 현 분석 디렉터리에 저장.
                    f.write(EXE_Binary_for_prediction)

                List_type_Dataset.append([f".\\{Get_sha256_from_exe}.exe",Get_sha256_from_exe, str(y[Max_index])])
                print([i for i in List_type_Dataset])
                with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'wb') as f:
                    pickle.dump(List_type_Dataset, f, protocol=5)

                '''
                    CSV에 등록
                '''
                from AI_Server.Parsing_CSV import Open_Csv  # CSV에 등록
                csv_editor = Open_Csv(self.Main_csv)
                if csv_editor.Write_to_Csv([f".\\{Get_sha256_from_exe}.exe",Get_sha256_from_exe, str(y[Max_index])]) :
                    print("CSV 성공")
            else:
                '''
                    CSV에 이미 존재하는 SHA256이 있다면, 그 행의 값을 최신화한다.
                '''
                print("최신화시도")
                from AI_Server.Parsing_CSV import Open_Csv  # CSV에 등록
                csv_editor = Open_Csv(self.Main_csv)
                if csv_editor.Rewrite_to_Csv(
                    Input_data=[f".\\{Get_sha256_from_exe}.exe", Get_sha256_from_exe, str(y[Max_index])],
                    is_ALL_change=False,
                    specified_hint=Get_sha256_from_exe,
                    index_hint=1,
                    is_Append_column_data=False,

                    Rewrite_column=False,
                    columns_list_for_Rewrite_column=None,
                    is_Append_for_Rewrite_column=False
                ):
                    print("CSV 성공")

                # 리스트도 최신화.
                List_type_Dataset = [ [f".\\{Get_sha256_from_exe}.exe", Get_sha256_from_exe, str(y[Max_index])]  if i[1] == Get_sha256_from_exe else i for i in List_type_Dataset ]
                print(List_type_Dataset)
                with open(f"{self.save_index}_List_type_Dataset_from_Pickle", 'wb') as f:
                    pickle.dump(List_type_Dataset, f, protocol=5)


            return y, struct.pack('<f', float(list(result)[0][Max_index])), str(y[Max_index])

'''test = AI_Static_Model_with_Vt(
    #Vt_API="b081a247f8bde7d98337dec2a44b9dff7d1eba19bd99a20c04395cea831177ee",
    Vt_API="da08a1b806802a568e78beb376605c9dc2dbd48f71cfbf0570c95dcb98a47c48",
    csv_path="C:\\Users\\Administrator\\PycharmProjects\\pythonProject\\AI_Server\\SHARE_ai_exe_dataset.csv",
    VT_analyse_csv="C:\\Users\\Administrator\\PycharmProjects\\pythonProject\\AI_Server\\VT_analysed.csv",
    save_index_For_PATH="idk"
)

import os


#test.Start_Train() # Disk CSV의 있는 것을 가지고 Train

# 자동화 EXE및 파일 가져오기
#[ [폴더] , [파일들]]
GET_FILES = []
for path, direct, files in os.walk("C:\\saver"):
    #print(f"{path}\n{direct}\n{files}")
    GET_FILES.append( [ path , files] )

print(GET_FILES)
for FILE_INFO_in_DISK in GET_FILES:
    for exe_file in FILE_INFO_in_DISK[1]:

        a = test.Prediction(EXE_PATH=f"C:\\saver\\{exe_file}")
        print(a)
        quit()'''
'''
num = 0
while (num < 2):
    test.Start_Train(epoch=300)

    for FILE_INFO_in_DISK in GET_FILES:
        for exe_file in FILE_INFO_in_DISK[1]:

            test.Prediction(EXE_PATH=f"C:\\saver\\{exe_file}") # CSV에 없으면 [exe경로,sha256,판단] 하거나, 이미 있으면 해당 row를 갱신.'''

#test.Start_Train()